{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOMCmjoFLw1L47A/xvJVhEI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssarker21/Introduction-to-Machine-Learning/blob/main/Homework5_problem2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBSnMeV2ucRd",
        "outputId": "ddbfcecb-aa63-4ab7-e318-0ead853febf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Training with lr=0.1 ===\n",
            "Epoch 1, Validation loss 25051734736896.0000, \n",
            "Epoch 2, Validation loss 15890309447680.0000, \n",
            "Epoch 3, Validation loss 10393048055808.0000, \n",
            "Epoch 500, Validation loss 1584917774336.0000, \n",
            "Epoch 1000, Validation loss 1584917774336.0000, \n",
            "Epoch 1500, Validation loss 1584917774336.0000, \n",
            "Epoch 2000, Validation loss 1584917774336.0000, \n",
            "Epoch 2500, Validation loss 1584917774336.0000, \n",
            "Epoch 3000, Validation loss 1584917774336.0000, \n",
            "Epoch 3500, Validation loss 1584917774336.0000, \n",
            "Epoch 4000, Validation loss 1584917774336.0000, \n",
            "Epoch 4500, Validation loss 1584917774336.0000, \n",
            "Epoch 5000, Validation loss 1584917774336.0000, \n",
            "Final (lr=0.1) -> Val loss: 1584917774336.000000, Val R^2: 0.416596\n",
            "\n",
            "=== Training with lr=0.01 ===\n",
            "Epoch 1, Validation loss 25051734736896.0000, \n",
            "Epoch 2, Validation loss 24026042859520.0000, \n",
            "Epoch 3, Validation loss 23046916145152.0000, \n",
            "Epoch 500, Validation loss 1584905977856.0000, \n",
            "Epoch 1000, Validation loss 1584915283968.0000, \n",
            "Epoch 1500, Validation loss 1584915415040.0000, \n",
            "Epoch 2000, Validation loss 1584915415040.0000, \n",
            "Epoch 2500, Validation loss 1584915415040.0000, \n",
            "Epoch 3000, Validation loss 1584915415040.0000, \n",
            "Epoch 3500, Validation loss 1584915415040.0000, \n",
            "Epoch 4000, Validation loss 1584915415040.0000, \n",
            "Epoch 4500, Validation loss 1584915415040.0000, \n",
            "Epoch 5000, Validation loss 1584915415040.0000, \n",
            "Final (lr=0.01) -> Val loss: 1584915415040.000000, Val R^2: 0.416597\n",
            "\n",
            "=== Training with lr=0.001 ===\n",
            "Epoch 1, Validation loss 25051734736896.0000, \n",
            "Epoch 2, Validation loss 24948070416384.0000, \n",
            "Epoch 3, Validation loss 24844880052224.0000, \n",
            "Epoch 500, Validation loss 4265941139456.0000, \n",
            "Epoch 1000, Validation loss 1853770170368.0000, \n",
            "Epoch 1500, Validation loss 1591118397440.0000, \n",
            "Epoch 2000, Validation loss 1575350697984.0000, \n",
            "Epoch 2500, Validation loss 1580024856576.0000, \n",
            "Epoch 3000, Validation loss 1583030337536.0000, \n",
            "Epoch 3500, Validation loss 1584259137536.0000, \n",
            "Epoch 4000, Validation loss 1584704389120.0000, \n",
            "Epoch 4500, Validation loss 1584854990848.0000, \n",
            "Epoch 5000, Validation loss 1584900603904.0000, \n",
            "Final (lr=0.001) -> Val loss: 1584900472832.000000, Val R^2: 0.416602\n",
            "\n",
            "=== Training with lr=0.0001 ===\n",
            "Epoch 1, Validation loss 25051734736896.0000, \n",
            "Epoch 2, Validation loss 25041355931648.0000, \n",
            "Epoch 3, Validation loss 25030983417856.0000, \n",
            "Epoch 500, Validation loss 20421097291776.0000, \n",
            "Epoch 1000, Validation loss 16721082580992.0000, \n",
            "Epoch 1500, Validation loss 13762273738752.0000, \n",
            "Epoch 2000, Validation loss 11390100176896.0000, \n",
            "Epoch 2500, Validation loss 9484186419200.0000, \n",
            "Epoch 3000, Validation loss 7950263910400.0000, \n",
            "Epoch 3500, Validation loss 6714015875072.0000, \n",
            "Epoch 4000, Validation loss 5716614578176.0000, \n",
            "Epoch 4500, Validation loss 4911292481536.0000, \n",
            "Epoch 5000, Validation loss 4260730765312.0000, \n",
            "Final (lr=0.0001) -> Val loss: 4259563700224.000000, Val R^2: -0.567935\n",
            "\n",
            "================== Best Linear Model ==================\n",
            "Chosen lr: 0.001\n",
            "Best Val loss: 1584900472832.000000\n",
            "Best Val R^2 : -0.567935\n",
            "\n",
            "Parameters in ORIGINAL UNITS (already scaled properly):\n",
            "W1 (area)      = 747587.187500\n",
            "W2 (bedrooms)  = 117459.289062\n",
            "W3 (bathrooms) = 607874.812500\n",
            "W4 (stories)   = 449469.000000\n",
            "W5 (parking)   = 359436.437500\n",
            "B (bias)       = 4776680.500000\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "# -------------------------\n",
        "# 0) Load dataset\n",
        "# -------------------------\n",
        "url = \"https://github.com/HamedTabkhi/Intro-to-ML/raw/main/Dataset/Housing.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Inputs (X1..X5) and target\n",
        "cols_X = [\"area\", \"bedrooms\", \"bathrooms\", \"stories\", \"parking\"]\n",
        "col_y  = \"price\"\n",
        "\n",
        "X_full = torch.tensor(df[cols_X].values, dtype=torch.float32)\n",
        "y_full = torch.tensor(df[col_y].values,  dtype=torch.float32)\n",
        "\n",
        "# -------------------------\n",
        "# 1) Split (80/20) exactly like slides pattern using randperm\n",
        "# -------------------------\n",
        "n_samples = X_full.shape[0]\n",
        "n_val = int(0.2 * n_samples)\n",
        "\n",
        "shuffled_indices = torch.randperm(n_samples)\n",
        "train_indices = shuffled_indices[:-n_val]\n",
        "val_indices   = shuffled_indices[-n_val:]\n",
        "\n",
        "train_X = X_full[train_indices]\n",
        "train_y = y_full[train_indices]\n",
        "\n",
        "val_X = X_full[val_indices]\n",
        "val_y = y_full[val_indices]\n",
        "\n",
        "# -------------------------\n",
        "# 2) Preprocessing (z-score only for input)\n",
        "# -------------------------\n",
        "X_mu  = train_X.mean(dim=0)\n",
        "X_std = train_X.std(dim=0) + 1e-8      # avoid divide-by-zero\n",
        "\n",
        "train_Xs = (train_X - X_mu) / X_std\n",
        "val_Xs   = (val_X   - X_mu) / X_std\n",
        "\n",
        "# Keep outputs (target) in original units\n",
        "train_ys = train_y\n",
        "val_ys   = val_y\n",
        "\n",
        "# -------------------------\n",
        "# 3) Model & Loss\n",
        "# -------------------------\n",
        "def model(t_u, w5, w4, w3, w2, w1, b):\n",
        "    # t_u columns: [area, bedrooms, bathrooms, stories, parking]\n",
        "    return (\n",
        "        w5 * t_u[:, 4] +   # parking  (X5)\n",
        "        w4 * t_u[:, 3] +   # stories  (X4)\n",
        "        w3 * t_u[:, 2] +   # bathrooms(X3)\n",
        "        w2 * t_u[:, 1] +   # bedrooms (X2)\n",
        "        w1 * t_u[:, 0] +   # area     (X1)\n",
        "        b\n",
        "    )\n",
        "\n",
        "def loss_fn(t_p, t_c):\n",
        "    return ((t_p - t_c) ** 2).mean()\n",
        "\n",
        "def r2_score(y_true, y_pred):\n",
        "    ss_res = ((y_true - y_pred)**2).sum()\n",
        "    ss_tot = ((y_true - y_true.mean())**2).sum()\n",
        "    return float(1.0 - ss_res / (ss_tot + 1e-12))\n",
        "\n",
        "# -------------------------\n",
        "# 4) Training loop\n",
        "# -------------------------\n",
        "def training_loop(n_epochs, optimizer, params, train_t_u, val_t_u, train_t_c, val_t_c):\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        # forward on train\n",
        "        train_t_p = model(train_t_u, *params)\n",
        "        train_loss = loss_fn(train_t_p, train_t_c)\n",
        "\n",
        "        # forward on validation (no backward)\n",
        "        with torch.no_grad():\n",
        "            val_t_p = model(val_t_u, *params)\n",
        "            val_loss = loss_fn(val_t_p, val_t_c)\n",
        "            val_r2   = r2_score(val_t_c, val_t_p)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch <= 3 or epoch % 500 == 0:\n",
        "            print(\n",
        "                f\"Epoch {epoch}, \"\n",
        "                f\"Validation loss {val_loss.item():.4f}, \"\n",
        "            )\n",
        "\n",
        "    return params\n",
        "\n",
        "# -------------------------\n",
        "# 5) Four trainings (lr: 0.1, 0.01, 0.001, 0.0001)\n",
        "# -------------------------\n",
        "lrs = [1e-1, 1e-2, 1e-3, 1e-4]\n",
        "results = {}\n",
        "\n",
        "for lr in lrs:\n",
        "    print(f\"\\n=== Training with lr={lr} ===\")\n",
        "    params = torch.zeros(6, requires_grad=True)  # [w5, w4, w3, w2, w1, b]\n",
        "    opt = optim.SGD([params], lr=lr)\n",
        "\n",
        "    final_params = training_loop(\n",
        "        n_epochs = 5000,\n",
        "        optimizer = opt,\n",
        "        params = params,\n",
        "        train_t_u = train_Xs,\n",
        "        val_t_u   = val_Xs,\n",
        "        train_t_c = train_ys,\n",
        "        val_t_c   = val_ys\n",
        "    )\n",
        "\n",
        "    with torch.no_grad():\n",
        "        val_pred = model(val_Xs, *final_params)\n",
        "        final_val_loss = float(loss_fn(val_pred, val_ys))\n",
        "        final_val_r2   = r2_score(val_ys, val_pred)\n",
        "\n",
        "    results[lr] = {\n",
        "        \"params\": final_params.detach().clone(),\n",
        "        \"val_loss\": final_val_loss,\n",
        "    }\n",
        "    print(f\"Final (lr={lr}) -> Val loss: {final_val_loss:.6f}, Val R^2: {final_val_r2:.6f}\")\n",
        "\n",
        "# -------------------------\n",
        "# 6) Pick best model by lowest validation loss\n",
        "# -------------------------\n",
        "best_lr = min(results, key=lambda k: results[k][\"val_loss\"])\n",
        "best = results[best_lr]\n",
        "w5, w4, w3, w2, w1, b = best[\"params\"]\n",
        "\n",
        "print(\"\\n================== Best Linear Model ==================\")\n",
        "print(f\"Chosen lr: {best_lr}\")\n",
        "print(f\"Best Val loss: {best['val_loss']:.6f}\")\n",
        "print(f\"Best Val R^2 : {final_val_r2:.6f}\")\n",
        "print(\"\\nParameters in ORIGINAL UNITS (already scaled properly):\")\n",
        "print(f\"W1 (area)      = {float(w1):.6f}\")\n",
        "print(f\"W2 (bedrooms)  = {float(w2):.6f}\")\n",
        "print(f\"W3 (bathrooms) = {float(w3):.6f}\")\n",
        "print(f\"W4 (stories)   = {float(w4):.6f}\")\n",
        "print(f\"W5 (parking)   = {float(w5):.6f}\")\n",
        "print(f\"B (bias)       = {float(b):.6f}\")"
      ]
    }
  ]
}
