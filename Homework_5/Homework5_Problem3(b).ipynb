{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNB5nunK3v1Sod5g7tD+xo+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssarker21/Introduction-to-Machine-Learning/blob/main/Homework5_Problem3(b).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0lmf8jv-ir9",
        "outputId": "2f8bd0f5-6d28-48f0-b8bf-80e14b60658c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model size (trainable parameters): 865\n",
            "Epoch   50 | Train Loss: 25569970356224.0000 | Val Loss: 28763450507264.0000 | Val R^2: -5.8004\n",
            "Epoch  100 | Train Loss: 25382247989248.0000 | Val Loss: 28550725894144.0000 | Val R^2: -5.7501\n",
            "Epoch  150 | Train Loss: 23962050363392.0000 | Val Loss: 26965509668864.0000 | Val R^2: -5.3753\n",
            "Epoch  200 | Train Loss: 19228027518976.0000 | Val Loss: 21706116694016.0000 | Val R^2: -4.1319\n",
            "\n",
            "=== Summary after 200 epochs (3 hidden layers) ===\n",
            "Training time: 0.34 seconds\n",
            "Final Train Loss (MSE): 19089336565760.0000\n",
            "Final Val  Loss (MSE): 21706116694016.0000\n",
            "Final Val  R^2 (accuracy): -4.1319\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# -------------------------\n",
        "# 0) Reproducibility & device\n",
        "# -------------------------\n",
        "torch.manual_seed(0)\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "# -------------------------\n",
        "# 1) Load data\n",
        "# -------------------------\n",
        "url = \"https://github.com/HamedTabkhi/Intro-to-ML/raw/main/Dataset/Housing.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Inputs and target (same as before)\n",
        "cols_X = [\"area\", \"bedrooms\", \"bathrooms\", \"stories\", \"parking\"]\n",
        "col_y  = \"price\"\n",
        "\n",
        "X = torch.tensor(df[cols_X].values, dtype=torch.float32)\n",
        "y = torch.tensor(df[col_y].values,  dtype=torch.float32).unsqueeze(1)  # (N,1)\n",
        "\n",
        "# -------------------------\n",
        "# 2) Train/Val split (80/20) â€” randperm (slide style)\n",
        "# -------------------------\n",
        "n_samples = X.shape[0]\n",
        "n_val = int(0.2 * n_samples)\n",
        "indices = torch.randperm(n_samples)\n",
        "train_idx = indices[:-n_val]\n",
        "val_idx   = indices[-n_val:]\n",
        "\n",
        "X_train = X[train_idx].to(device)\n",
        "y_train = y[train_idx].to(device)\n",
        "X_val   = X[val_idx].to(device)\n",
        "y_val   = y[val_idx].to(device)\n",
        "\n",
        "# -------------------------\n",
        "# 3) Standardize features using TRAIN stats\n",
        "# -------------------------\n",
        "x_mean = X_train.mean(dim=0, keepdim=True)\n",
        "x_std  = X_train.std(dim=0, keepdim=True).clamp_min(1e-8)\n",
        "\n",
        "X_train_std = (X_train - x_mean) / x_std\n",
        "X_val_std   = (X_val   - x_mean) / x_std\n",
        "\n",
        "# -------------------------\n",
        "# 4) Model: three hidden layers (e.g., 5 -> 32 -> 16 -> 8 -> 1)\n",
        "# -------------------------\n",
        "class DeepNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(5, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 8),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(8, 1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "model = DeepNet().to(device)\n",
        "\n",
        "# Utility: count trainable parameters (model size)\n",
        "def count_params(m):\n",
        "    return sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"Model size (trainable parameters): {count_params(model)}\")\n",
        "\n",
        "# -------------------------\n",
        "# 5) Training setup\n",
        "# -------------------------\n",
        "criterion = nn.MSELoss()                 # regression loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
        "epochs = 200\n",
        "\n",
        "def r2_score(y_true, y_pred):\n",
        "    y_mean = y_true.mean()\n",
        "    ss_res = torch.sum((y_true - y_pred) ** 2)\n",
        "    ss_tot = torch.sum((y_true - y_mean) ** 2)\n",
        "    if ss_tot.item() == 0.0:\n",
        "        return torch.tensor(0.0, device=y_true.device)\n",
        "    return 1.0 - ss_res / ss_tot\n",
        "\n",
        "# -------------------------\n",
        "# 6) Train (200 epochs)\n",
        "# -------------------------\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    y_pred_train = model(X_train_std)\n",
        "    loss_train = criterion(y_pred_train, y_train)\n",
        "    loss_train.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 50 == 0 or epoch == epochs:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            y_pred_val = model(X_val_std)\n",
        "            loss_val = criterion(y_pred_val, y_val)\n",
        "            r2_val = r2_score(y_val, y_pred_val)\n",
        "        print(f\"Epoch {epoch:4d} | Train Loss: {loss_train.item():.4f} \"\n",
        "              f\"| Val Loss: {loss_val.item():.4f} | Val R^2: {r2_val.item():.4f}\")\n",
        "\n",
        "train_time_sec = time.time() - start_time\n",
        "\n",
        "# -------------------------\n",
        "# 7) Final report\n",
        "# -------------------------\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    final_train_loss = criterion(model(X_train_std), y_train).item()\n",
        "    final_val_pred   = model(X_val_std)\n",
        "    final_val_loss   = criterion(final_val_pred, y_val).item()\n",
        "    final_val_r2     = r2_score(y_val, final_val_pred).item()\n",
        "\n",
        "print(\"\\n=== Summary after 200 epochs (3 hidden layers) ===\")\n",
        "print(f\"Training time: {train_time_sec:.2f} seconds\")\n",
        "print(f\"Final Train Loss (MSE): {final_train_loss:.4f}\")\n",
        "print(f\"Final Val  Loss (MSE): {final_val_loss:.4f}\")\n",
        "print(f\"Final Val  R^2 (accuracy): {final_val_r2:.4f}\")"
      ]
    }
  ]
}
